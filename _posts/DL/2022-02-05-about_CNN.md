---
title: "CNN이란 무엇인가?"
categories: DL
toc: true
toc_sticky: true
use_math: true
---


> 이 글은 OpenAI의 ChatGPT를 이용하여 생성된 글입니다. ChatGPT최고..!

CNN(Convolutional Neural Networks)은 이미지 분류 및 객체 인식 작업에 일반적으로 사용되는 일종의 심층 학습 신경망이다.  
CNN은 입력 이미지를 처리하고 여기에서 특징을 추출하는 여러 Layer으로 구성된다.  
레이어는 크게 컨볼루션 레이어, 활성화 레이어 및 완전 연결 레이어의 세 가지 유형으로 나눌 수 있다. 완전 연결 레이어(Fully Connected Layer)는 Dense Layer라고도 한다.

### 동작과정
1. 입력: 일반적으로 이미지 형태인 입력 데이터는 네트워크에 공급되기 전에 shape변환이나 정규화로 사전 처리된다. 
2. 컨볼루션 작업: 입력은 하나 이상의 컨볼루션 레이어를 통과하며, 여기서 학습 가능한 필터 집합이 입력과 컨볼루션되어 피처 맵을 생성한다. 필터 stride와 padding을 통해 가장자리, 모서리 같은 특정을 탐지할 수 있다.
3. 비선형 활성화: 피처 맵은 ReLU 활성화와 같은 비선형 활성화 기능을 통해 전달되어 네트워크에 비선형성을 도입한다.
4. 풀링 작업: 활성화 레이어의 출력이 풀링 레이어를 통과한다. 풀링 레이어에서는 로컬 영역에서 최대값 또는 평균값을 취하여 피처 맵의 공간 해상도가 감소한다. 이는 입력에서 중요한 기능을 감지하는 기능을 유지하면서 네트워크의 계산 복잡성을 줄이는 데 도움이 된다.
5. 반복: 컨볼루션, 활성화 및 풀링 프로세스를 여러 번 반복하여 네트워크에 여러 개의 Layer을 형성할 수 있다.
6. FC레이어 작업: 풀링 레이어의 최종 출력은 하나 또는 여러 개의 완전 연결 레이어를 통과하며 여기에서 피처는 입력 이미지에 대한 예측으로 변환된다.


### Convolutional Layers
Convolutional Layer는 CNN에서 시각적 데이터를 처리하기 위한 기본 Layer이다. 피처 맵을 계산하기 위해 입력 데이터와 컨벌루션되는 학습 가능한 필터 세트로 구성된다.  
컨볼루션 연산은 입력 데이터 위로 필터를 밀고 필터 항목과 입력의 겹치는 항목 사이의 내적을 계산하여 수행된다.  
그런 다음 내적을 합산하여 단일 스칼라를 생성하고 이 스칼라는 피처 맵에서 해당 요소의 값이 된다. 그림에서 노란색 박스가 필터이다.

![gif](assets/images/CNN/cnn_filter.gif)  

패딩은 컨볼루션 전에 입력 데이터 주위에 0의 테두리를 추가하는 것을 말한다. 이는 입력의 공간 차원을 보존하는 데 도움이 되므로 출력 피처 맵이 입력과 동일한 공간 차원을 가질 수 있다. 이는 입력의 공간 구조를 보존하고 경계에서 정보 손실을 방지하는 데 유용하다.  

![gif](assets/images/CNN/cnn_padding.gif)  

스트라이드는 컨볼루션 연산의 단계 크기를 나타낸다. stride는 출력 피처 맵의 공간 해상도를 결정한다. stride가 1이면 출력은 입력과 동일한 해상도를 갖는다. stride가 1보다 크면 출력의 해상도가 낮아져 기능 맵의 크기가 효과적으로 줄어든다. 이는 계산 복잡성을 줄이고 입력 데이터에서 더 큰 피처를 감지하는 네트워크의 기능을 향상시키는 데 도움이 될 수 있다. 왼쪽은 stride가 1일때, 오른쪽은 stride가 2일때이다.  

<p align="center">
  <img src="assets/images/CNN/cnn_stride1.gif" align="center" width="49%">
  <img src="assets/images/CNN/cnn_stride2.gif" align="center" width="49%">
</p>

각 필터에는 고유한 가중치 세트가 있으며 이러한 가중치는 입력 이미지에서 가장 관련성이 높은 피처를 학습하기 위해 훈련 중에 업데이트된다.  
따라서 필터는 훈련 과정 중에 입력 이미지에서 관련 기능을 추출하는 방법을 학습한다.  

### Activation Layers
Convolutional Layer의 출력은 ReLU 활성화와 같은 비선형 활성화 함수를 통과하여 네트워크에 비선형성을 도입한다. 활성화 함수는 컨볼루션 레이어의 출력에 요소별로 적용되어 입력과 학습된 필터 사이의 복잡하고 비선형적인 관계를 나타낼 수 있는 새로운 피처 맵을 생성한다.

### Pooling Layers
Activation Layer의 출력은 Pooling Layer를 통과하며, 여기에서 로컬 영역에 대해 최대값 또는 평균값을 취함으로써 피처 맵의 공간 해상도가 감소한다. 풀링 작업은 특징 맵을 겹치지 않는 영역으로 나누고 각 영역에 대한 최대값 또는 평균값을 계산하여 수행된다.

![png](assets/images/CNN/cnn_pooling.png)


### Flatten Layer
이전 레이어의 다차원 출력을 FC Layer에 입력할 수 있도록 1D 배열로 변환하는 데 사용된다. 일반적으로 Conv2D 또는 MaxPooling2D 레이어인 이전 레이어의 출력은 (batch_size, height, width, channels)와 같은 다차원 모양을 갖는데, Flatten Layer는 이 출력을 가져와 모양의 1D 배열(batch_size, height * width * channels)로 "평탄화"한다. 이는 Dense Layer가 1D 배열만 입력으로 받을 수 있기 때문이다.  

![png](assets/images/CNN/cnn_flatten.png)

### FC Layers
Polling Layer의 최종 출력은 Flatten Layer를 거쳐 하나 이상의 FC Layer를 통과한다. FC Layer에서 Layer의 각 단위는 이전 레이어의 모든 단위에 연결되며 입력과 가중치의 내적을 계산하여 출력을 생성한다. FC Layer는 피처 맵에 포함된 전역 정보에 대해 작동하여 정보를 결합하고 최종 예측으로 변환한다. 

### Training and Optimization
CNN의 마지막 단계는 레이블이 지정된 데이터 세트에서 훈련하는 것이다. 훈련의 목표는 예측된 출력과 실제 출력 사이의 오류가 최소화되도록 네트워크에서 필터와 FC Layer의 가중치와 편향을 조정하는 것이다.  
최적화 프로세스는 일반적으로 경사 하강법 알고리즘과 역전파를 사용하여 수행된다. 손실 함수의 선택은 훈련의 목적에 따라 달라진다. 예를 들어 이미지 분류 문제의 경우 일반적으로 사용되는 손실 함수는 Categorical Cross Entropy와 MSE이다.  


![jpg](assets/images/CNN/cnn_structure.jpg)  

### CNN Structure


위의 그림은 CNN의 구조에 대해서 나타낸것이다. Layer의 통과 과정을 대략적으로 살펴보자. 위에서 배운대로 <span style="color:violet">input -> Conv Layer -> Pooling Layer -> Conv Layer -> Pooling Layer -> Flatten Layer -> FC Layer -> Fc Layer -> output</span> 순서로 통과한다.

조금 더 심화적으로 들어가서 각 레이어마다 출력되는 Shape을 계산해보자. 
* 필터수: F
* 입력 데이터의 높이: H
* 입력 데이터의 폭: W
* 필터 높이 : FH
* 필터 폭: FW
* Stride 크기: S
* Padding 크기: P  

**Convolution Layer 출력**  
$OutputHeight = {H + 2P - FH \over S}+1$  
</br>
$OutputWidth = {W + 2P - FW \over S} +1$  
</br>
$Chennel = F$  

**Pooling Layer 출력**  
$OutputHeight = {InputHeight \over PoolingSize}$  
</br>
$OutputWidth = {InputWidth \over PoolingSize}$

우선 첫번째 Conv Layer를 계산해보자.  
input의 너비와 높이가 같으므로 계산식은 (28 + 0 - 5 + 1)이므로 24가 된다. 그리고 채널은 필터수 이므로 32가 된다.  
따라서 (24, 24, 32)가 된다.
그다음 Pooling Layer는 이전 output(Conv Layer)에 풀링 크기만 나눠주므로 (12, 12, 32)가 된다.  

***여기서 주의할 점은 각 크기는 자연수가 되어야 하고, Conv Layer 다음 Pooling Layer가 온다면, 피처맵의 행과 열 크기는 Pooling크기의 배수여야 한다. 이 조건을 만족하도록 filter의 크기 및 stride, padding크기를 조절하여야 한다.***
